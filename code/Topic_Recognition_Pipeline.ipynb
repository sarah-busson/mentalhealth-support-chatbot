{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the pipeline works ?\n",
    "\n",
    "If implemented in a chatbot, this model in based on the user input. So I have to transform the input (raw text), into a vectorized form of the input text, then run the prediction and return the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "topic_rec = tf.keras.models.load_model('topic_text_1000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey bud! What's wrong.. do you wanna talk about it ? ü§ó \n",
      "I over-portion/over-do everything Maybe it‚Äôs for comfort, but I always dish up so much food, or use so much lotion or lip balm, or drink a lot, or smoke a lot, or use a lot of perfume, or spend so much money. Literally anything that can be overdone, i over do it. I don‚Äôt understand why I do this and it‚Äôs not as easy as ‚Äújust dish up less‚Äù... because it‚Äôs infiltrated in everything I do. Help?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = input(\"Hey bud! What's wrong.. do you wanna talk about it ? ü§ó \\n\")\n",
    "type(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll use spacy as it seemed like a good option to lemmatize with the appropriate pos tag, detects pronouns and superlative \n",
    "#forms of words.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "#Clean the text:\n",
    "def clean_input(s):\n",
    "    s = s.lower()                   #remove caps to avoid double words\n",
    "    s = re.sub('[\\W\\d]', ' ', s)    #remove special signs, punctuation, numbers\n",
    "    s = re.sub(' +', ' ', s)        #remove excessive spaces\n",
    "    s = s.strip()                   #remove first and last spaces\n",
    "    return s\n",
    "\n",
    "def spacy_lem(l):\n",
    "    doc = nlp(l)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "word_features_topic = pd.read_csv('../data/word_features_topic.csv')\n",
    "word_features = list(word_features_topic['0'])\n",
    "\n",
    "def vectorize_input(l):\n",
    "    new_list = []\n",
    "    for word in word_features:\n",
    "        if word in l:\n",
    "            new_list.append(1)\n",
    "        else:\n",
    "            new_list.append(0)\n",
    "    return new_list\n",
    "\n",
    "topics = {'SPIRITUALITY':0,\n",
    "          'COUNSELING':1,\n",
    "          'WORKPLACE':2,\n",
    "          'FAMILY':3,\n",
    "          'RELATIONSHIPS':4,\n",
    "          'SLEEP':5,\n",
    "          'BEHAVIOR':6,\n",
    "          'SEXUALITY':7,\n",
    "          'SELF_ESTEEM':8,\n",
    "          'GRIEF':9,\n",
    "          'TRAUMA':10,\n",
    "          'STRESS':11,\n",
    "          'EATING_DISORDERS':12,\n",
    "          'ADDICTION':13,\n",
    "          'DEPRESSION':14,\n",
    "          'LGBTQ':15,\n",
    "          'DOMESTIC_VIOLENCE':16,\n",
    "          'SELF_HARM':17}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = clean_input(raw_text)\n",
    "lem_text = spacy_lem(clean_text)\n",
    "vect_text = vectorize_input(lem_text)\n",
    "\n",
    "\n",
    "type(np.array(vect_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = topic_rec.predict([vect_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[4.3599198e-06 5.1479746e-04 6.6560456e-06 3.8392644e-04 6.9331891e-06\n",
      " 5.6064946e-05 2.3698327e-04 2.3333209e-04 3.1701962e-03 1.2232776e-04\n",
      " 7.6867198e-04 5.9286575e-03 1.9935238e-04 9.8432910e-01 3.7060697e-03\n",
      " 2.5700062e-04 2.1533733e-05 5.4005955e-05]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(pred))\n",
    "for i in pred:\n",
    "    if i.any() > 0.1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDICTION\n"
     ]
    }
   ],
   "source": [
    "for key in topics:\n",
    "    if np.argmax(pred) == topics[key]:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_recognizer():\n",
    "    raw_text = input(\"Hey bud! What's wrong.. do you wanna talk about it ? ü§ó \\n\\n\")\n",
    "\n",
    "    vect_text = vectorize_input(spacy_lem(clean_input(raw_text)))\n",
    "#    vect_text = np.array(vect_text)\n",
    "    pred = topic_rec.predict([vect_text])\n",
    "\n",
    "    recognized_topics = []\n",
    "    \n",
    "    for key in topics: \n",
    "        if np.max(pred) > 0.5:\n",
    "            if np.argmax(pred) == topics[key]:\n",
    "                recognized_topics.append((key, round((pred[0][np.argmax(pred)])*100, 2)))\n",
    "        else:\n",
    "            for p in (-pred).argsort():\n",
    "                for top in p[:3]:\n",
    "                    if top == topics[key]:\n",
    "                        recognized_topics.append((key, pred[0][top]))\n",
    "\n",
    "    return recognized_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey bud! What's wrong.. do you wanna talk about it ? ü§ó \n",
      "\n",
      "I over-portion/over-do everything Maybe it‚Äôs for comfort, but I always dish up so much food, or use so much lotion or lip balm, or drink a lot, or smoke a lot, or use a lot of perfume, or spend so much money. Literally anything that can be overdone, i over do it. I don‚Äôt understand why I do this and it‚Äôs not as easy as ‚Äújust dish up less‚Äù... because it‚Äôs infiltrated in everything I do. Help?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ADDICTION', 98.43)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_topics = topic_recognizer()\n",
    "recognized_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ADDICTION', 98.43)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognized_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
