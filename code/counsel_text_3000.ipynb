{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#I'll use spacy as it seemed like a good option to lemmatize with the appropriate pos tag, detects pronouns and superlative \n",
    "#forms of words.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words.append('-PRON-') #remove it as it won't be necessary in our model\n",
    "stop_words.append('p')\n",
    "stop_words.append('nbsp') #this is the '<p>' and &nbsp from the html conversion\n",
    "\n",
    "#Clean the text:\n",
    "def clean_chat(s):\n",
    "    s = str(s)\n",
    "    s = s.lower()                   #remove caps to avoid double words\n",
    "    s = re.sub('[\\W\\d]', ' ', s)    #remove special signs, punctuation, numbers\n",
    "    s = re.sub(' +', ' ', s)        #remove excessive spaces\n",
    "    s = s.strip()                   #remove first and last spaces\n",
    "    return s\n",
    "\n",
    "def spacy_lem(l):\n",
    "    doc = nlp(l)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Escalating disagreements between mother and wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>I'm addicted to smoking. How can I stop? I'm p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Keeping secrets from my family I have secrets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>The Underlying Causes of Being Possessive I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Can I control anxiety without medication? I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>2</td>\n",
       "      <td>What happens in a counseling session? After fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>2</td>\n",
       "      <td>What happens in a counseling session? After fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>2</td>\n",
       "      <td>What happens in a counseling session? After fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>2</td>\n",
       "      <td>What happens in a counseling session? After fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>2</td>\n",
       "      <td>What happens in a counseling session? After fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3601 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                           sentence\n",
       "0         4  Escalating disagreements between mother and wi...\n",
       "1        14  I'm addicted to smoking. How can I stop? I'm p...\n",
       "2         4  Keeping secrets from my family I have secrets ...\n",
       "3         7  The Underlying Causes of Being Possessive I am...\n",
       "4        12  Can I control anxiety without medication? I ha...\n",
       "...     ...                                                ...\n",
       "2124      2  What happens in a counseling session? After fi...\n",
       "2125      2  What happens in a counseling session? After fi...\n",
       "2126      2  What happens in a counseling session? After fi...\n",
       "2127      2  What happens in a counseling session? After fi...\n",
       "2128      2  What happens in a counseling session? After fi...\n",
       "\n",
       "[3601 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatc1 = pd.read_csv('../data/counsel-chat.txt')\n",
    "chatc2 = pd.read_csv('../data/scrap-counsel-chat.txt') \n",
    "\n",
    "chatc1.drop(['questionID','questionUrl','therapistName','therapistUrl','upvotes'], axis=1, inplace=True)\n",
    "chatc2.drop(['Unnamed: 0','questionID','questionLink','therapistInfo','therapistURL','upvotes','views','split'], axis=1, inplace=True)\n",
    "\n",
    "chatc1.rename(columns={'topics':'topic'}, inplace=True)\n",
    "\n",
    "counsel_cat = pd.concat([chatc1, chatc2])\n",
    "\n",
    "counsel_cat['sentence'] = counsel_cat.questionTitle.fillna('') +' '+ counsel_cat.questionText.fillna('') +' '+ counsel_cat.answerText.fillna('')\n",
    "counsel_cat.drop(['questionTitle', 'questionText', 'answerText'], axis=1, inplace=True)\n",
    "\n",
    "counsel_cat.topic = counsel_cat.topic.apply(lambda x: str(x).lower())\n",
    "counsel_cat.topic = counsel_cat.topic.apply(lambda x: str(x).strip())\n",
    "\n",
    "counsel_cat.replace('nan', np.nan, inplace=True)\n",
    "counsel_cat.dropna(inplace=True)\n",
    "\n",
    "counsel_cat.replace('-', ' ', regex=True, inplace=True)\n",
    "\n",
    "topic = counsel_cat.topic.unique()\n",
    "topic = [str(word).split(',') for word in topic]\n",
    "topic = [word for lst in topic for word in lst]\n",
    "#Ok that's a lot of topics, let's try to reduce them not by deleting but make some topics more general\n",
    "topic = np.unique(topic)\n",
    "\n",
    "\"\"\"\n",
    "- Substance abuse and Addiction are related topics -> ADDICTION,\n",
    "- Anxiety and stress are realted topics -> STRESS,\n",
    "- Relationships, social relationships, relationship dissolution, Marriage are related topics -> RELATIONSHIPS,\n",
    "- Children and Adolescents, Family Conflict, Parenting, Alzheimer's are related topics -> FAMILY,\n",
    "- Career Counseling, Professional Ethics, Workplace Relationship are related topics -> WORKPLACE,\n",
    "- Human Sexuality and Intimacy -> SEXUALITY\n",
    "- Counseling fundamentals, Legal & Regulatory, Military Issues and Diagnosis -> COUNSELING\n",
    "- Behaviorall change, anger management -> BEHAVIOR\n",
    "\n",
    "'SPIRITUALITY' = 1\n",
    "'COUNSELING' = 2\n",
    "\n",
    "'WORKPLACE' = 3\n",
    "'FAMILY' = 4\n",
    "'RELATIONSHIPS' = 5\n",
    "'SLEEP' = 6\n",
    "'BEHAVIOR' = 7\n",
    "'SEXUALITY' = 8\n",
    "'SELF_ESTEEM' = 9\n",
    "'GRIEF' = 10\n",
    "'TRAUMA' = 11\n",
    "\n",
    "'STRESS' = 12\n",
    "'EATING_DISORDERS' = 13\n",
    "'ADDICTION' = 14\n",
    "'DEPRESSION' = 15\n",
    "'LGBTQ' = 16\n",
    "\n",
    "'DOMESTIC_VIOLENCE' = 17\n",
    "'SELF_HARM' = 18\n",
    "\"\"\"\n",
    "\n",
    "topic_dict = {'addiction':'14',\n",
    "              \"alzheimer's\":'4',\n",
    "              'anger management':'7',\n",
    "              'anxiety':'12',\n",
    "              'behavioral change':'7',\n",
    "              'career counseling':'3',\n",
    "              'children & adolescents':'4',\n",
    "              'children adolescents':'4',\n",
    "              'counseling fundamentals':'2',\n",
    "              'depression':'15',\n",
    "              'diagnosis':'2',\n",
    "              'domestic violence':'17',\n",
    "              'eating disorders':'13',\n",
    "              'family conflict':'4',\n",
    "              'grief and loss':'10',\n",
    "              'human sexuality':'8',\n",
    "              'intimacy':'8',\n",
    "              'lgbtq':'16',\n",
    "              'legal & regulatory':'2',\n",
    "              'legal regulatory':'2',\n",
    "              'marriage':'5',\n",
    "              'military issues':'2',\n",
    "              'parenting':'4',\n",
    "              'professional ethics':'3',\n",
    "              'dissolution':'5',\n",
    "              'relationships':'5',\n",
    "              'relationship':'5',\n",
    "              'self esteem':'9',\n",
    "              'self harm':'18',\n",
    "              'sleep improvement':'6',\n",
    "              'social':'5',\n",
    "              'spirituality':'1',\n",
    "              'stress':'12',\n",
    "              'substance abuse':'14',\n",
    "              'trauma':'11',\n",
    "              'workplace':'3'}\n",
    "\n",
    "for key in topic_dict:\n",
    "    counsel_cat.topic = counsel_cat.topic.str.replace(key, topic_dict[key], regex=False)\n",
    "\n",
    "#topic_red = counsel_cat.topic.unique()\n",
    "\n",
    "def sort_topics(s):\n",
    "    s = str(s)\n",
    "    s = re.findall('\\d+', s)\n",
    "    s = [int(number) for number in s]\n",
    "    return max(s)  \n",
    "\n",
    "#sort_topics(counsel_cat.topic[1])\n",
    "\n",
    "counsel_cat.topic = counsel_cat.topic.apply(sort_topics)\n",
    "\n",
    "counsel_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counsel_cat.sentence = counsel_cat.sentence.apply(clean_chat)\n",
    "counsel_cat.sentence = counsel_cat.sentence.apply(spacy_lem)\n",
    "\n",
    "counsel_cat.sentence = counsel_cat.sentence.apply(lambda x: np.unique([word for word in x if word not in stop_words]))\n",
    "\n",
    "all_sentence = list(counsel_cat.sentence)\n",
    "bow_sentence = [word for lst in all_sentence for word in lst]\n",
    "all_words = nltk.FreqDist(bow_sentence)\n",
    "\n",
    "#Get 3000 most common words\n",
    "word_tuples = all_words.most_common(3000)\n",
    "word_features = [x[0] for x in word_tuples]\n",
    "\n",
    "#word_tuples\n",
    "word_features\n",
    "\n",
    "def vectorize_topic(l):\n",
    "    new_list = []\n",
    "    for word in word_features:\n",
    "        if word in l:\n",
    "            new_list.append(1)\n",
    "        else:\n",
    "            new_list.append(0)\n",
    "    return new_list\n",
    "\n",
    "counsel_cat.sentence = counsel_cat.sentence.apply(vectorize_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(counsel_cat.sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "counsel_cat.reset_index(inplace=True)\n",
    "counsel_cat.to_json('../data/counsel_text_3000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510     7\n",
       "1056    12\n",
       "2865     4\n",
       "2380     5\n",
       "1520    15\n",
       "        ..\n",
       "2310     5\n",
       "2507     7\n",
       "1652    15\n",
       "2351     5\n",
       "79      12\n",
       "Name: topic, Length: 2600, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counsel = counsel_cat.sample(frac=1)\n",
    "\n",
    "X = counsel.sentence\n",
    "y = counsel.topic\n",
    "\n",
    "X_train = np.vstack(X[:2600])\n",
    "X_test = np.vstack(X[2600:])\n",
    "\n",
    "y_train = y[:2600]\n",
    "y_test = y[2600:]\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 2s 26ms/step - loss: 1.6601 - accuracy: 0.4973\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 2s 26ms/step - loss: 0.4809 - accuracy: 0.8619\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.2676 - accuracy: 0.9115\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.1969 - accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 2s 26ms/step - loss: 0.1661 - accuracy: 0.9212\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.1496 - accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 2s 27ms/step - loss: 0.1311 - accuracy: 0.9308\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 2s 26ms/step - loss: 0.1273 - accuracy: 0.9323\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.1288 - accuracy: 0.9265\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 2s 26ms/step - loss: 0.1371 - accuracy: 0.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2211cea5908>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1000, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1000, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1000, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(19, activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1862 - accuracy: 0.7373\n",
      "1.1861701011657715 0.7372627258300781\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 3000) dtype=int32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "[[4.9297766e-10 4.7433739e-05 1.1202094e-06 ... 5.4058578e-04\n",
      "  3.3883800e-06 4.9867435e-07]\n",
      " [3.4647307e-10 3.1541713e-06 5.4678430e-06 ... 7.7109507e-05\n",
      "  5.7253342e-06 7.2889868e-08]\n",
      " [6.3856127e-14 4.1078501e-08 3.4451190e-08 ... 1.9922632e-07\n",
      "  5.4727035e-08 2.1641214e-10]\n",
      " ...\n",
      " [1.1167561e-11 5.8293222e-07 9.9702150e-01 ... 2.2194665e-06\n",
      "  2.9729316e-07 6.5831905e-08]\n",
      " [1.3016181e-12 1.0136028e-08 3.3463814e-06 ... 8.6897370e-07\n",
      "  1.5025297e-07 4.8088973e-09]\n",
      " [3.2794394e-12 9.4900074e-08 6.5463697e-05 ... 5.1656412e-09\n",
      "  7.7361577e-08 1.3182629e-04]]\n",
      "2822     4\n",
      "1390    14\n",
      "3002     5\n",
      "2307     5\n",
      "2074     4\n",
      "        ..\n",
      "445     15\n",
      "2715     8\n",
      "3515     2\n",
      "1978    12\n",
      "1562    15\n",
      "Name: topic, Length: 1001, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predic = model.predict([X_test])\n",
    "print(predic)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predic[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
